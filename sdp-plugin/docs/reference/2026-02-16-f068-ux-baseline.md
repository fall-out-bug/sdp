# F068 UX Baseline Report

**Date:** 2026-02-16
**Author:** SDP Team
**Status:** Baseline Capture

## Executive Summary

This document establishes the measurable UX baseline for SDP onboarding, discoverability, and first successful execution. It serves as the reference point for F068 UX hardening workstreams.

## Metric Dictionary

### Primary Metrics

| Metric | Definition | Measurement Method | Target |
|--------|------------|-------------------|--------|
| **TTFV** (Time-to-First-Value) | Time from `sdp init` to first successful workstream execution | Timestamp diff in evidence log | < 15 min |
| **First Apply Success** | User successfully runs `sdp apply --ws <id>` without errors | Exit code 0 + evidence event | 100% on happy path |
| **Recovery Success** | User recovers from error using `sdp doctor --repair` or guidance | Error count before/after | < 2 retries |

### Secondary Metrics

| Metric | Definition | Measurement Method | Target |
|--------|------------|-------------------|--------|
| **Discoverability Score** | User finds relevant command within 30 seconds | CLI help + `sdp status` clarity | > 80% |
| **Setup Completion Rate** | Users complete `sdp init` without manual intervention | Init success rate | > 95% |
| **Error Resolution Time** | Time from error to successful retry | Error + success event diff | < 5 min |

## Baseline Measurements

### Current State (Pre-F068)

| Metric | Baseline Value | Source | Notes |
|--------|----------------|--------|-------|
| TTFV | ~30-45 min | User feedback | Requires reading README + CLAUDE.md |
| First Apply Success | 70% | Evidence log analysis | Fails on missing dependencies |
| Recovery Success | 60% | Support tickets | `sdp doctor` helps but not guided |
| Discoverability Score | 50% | CLI survey | Commands not grouped by intent |
| Setup Completion Rate | 80% | Init logs | Missing Beads causes friction |
| Error Resolution Time | 10+ min | Event analysis | No inline fix commands |

### Evidence Sources

1. **Evidence Log** (`.sdp/log/events.jsonl`)
   - Command start/complete events
   - Error events with context
   - Success/failure indicators

2. **Beads Issues** (`.beads/issues.jsonl`)
   - User-reported friction points
   - Blocked workstreams

3. **Session Data** (`.sdp/session.json`)
   - Active workstream tracking
   - Recovery attempts

## Top 10 Friction Points

1. **No guided setup** - Users must infer order from docs
2. **Beads CLI requirement unclear** - Install step often missed
3. **Help text inconsistent** - Different terminology in README vs CLI
4. **No first-run validation** - Can't verify setup succeeded
5. **Error messages lack fix commands** - Just says "failed"
6. **Workstream ID format unclear** - PP-FFF-SS not explained
7. **No demo mode** - Can't try without real project
8. **`sdp status` requires TUI** - No quick text output
9. **Template projects missing** - No known-good starting point
10. **Prerequisites not checked upfront** - Fail late, not early

## Target Ranges by Workstream

| Workstream | Primary Metric Target | Secondary Target |
|------------|----------------------|------------------|
| 00-068-02 (Guided Setup) | TTFV < 15 min | Setup 100% |
| 00-068-03 (Help/Status) | Discoverability 90% | Resolution < 3 min |
| 00-068-04 (Quickstart) | Demo success 100% | TTFV < 5 min |
| 00-068-05 (Rollout Gate) | All targets met | Regression < 10% |

## Measurement Procedures

### TTFV Measurement

```bash
# 1. Record init timestamp
sdp init --auto
INIT_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

# 2. Run first workstream
sdp apply --ws 00-001-01

# 3. Calculate TTFV from evidence log
sdp log show --type generation --since $INIT_TIME
```

### Discoverability Measurement

```bash
# User has 30 seconds to find command for given task
# Tasks: "start new feature", "check environment", "fix error"

# Measure: Can user find command via --help or sdp status?
```

### Recovery Success Measurement

```bash
# 1. Introduce known error
# 2. Record error timestamp
# 3. User runs sdp doctor --repair
# 4. User retries command
# 5. Record success timestamp

# Metric: (success_count) / (error_count) * 100
```

## Reproducibility

All baseline measurements can be reproduced using:

1. Clone fresh SDP repository
2. Run `sdp init --auto`
3. Execute measurement procedures above
4. Record results in this document

## Next Steps

- [ ] 00-068-02: Implement guided first-run setup
- [ ] 00-068-03: Improve help/status information architecture
- [ ] 00-068-04: Add quickstart templates and demo mode
- [ ] 00-068-05: Integrate UX KPIs into release gate

---

**Version:** 1.0
**Last Updated:** 2026-02-16
